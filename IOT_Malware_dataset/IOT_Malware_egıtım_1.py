
import os, warnings, joblib, shutil, json, time
from pathlib import Path
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from skimage.feature import hog

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

# TensorFlow (opsiyonel) ------------------------------------------------------
try:
    import tensorflow as tf
    from tensorflow.keras.applications import MobileNetV2
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
    HAS_TF = True
except ImportError:
    HAS_TF = False

# ‚îÄ‚îÄ‚îÄ Dosya Yollarƒ± -----------------------------------------------------------
ROOT = Path(r"C:\Users\ƒ∞SO\Desktop\VERI_SETLERI\IOT_Malware_dataset")
PROC = ROOT / "processed"; PROC.mkdir(exist_ok=True)
CM_DIR = PROC / "model_cms"; CM_DIR.mkdir(exist_ok=True)
IMG_SIZE = (128,128)
SEED = 42

LABELS = {"Benign":0, "Malware":1}

# ‚îÄ‚îÄ‚îÄ Yardƒ±mcƒ± Fonksiyonlar ----------------------------------------------------

def gather_images(folder: Path, label: int):
    imgs = []
    for ext in ("*.jpg","*.jpeg","*.png"):
        imgs.extend(folder.rglob(ext))
    print(f"  {folder.name}: {len(imgs)} g√∂rsel")
    return [(p, label) for p in imgs]

def extract_features(path: Path):
    try:
        img = Image.open(path).convert("L").resize(IMG_SIZE)
        arr = np.array(img)
    except Exception:
        return None
    hist, _ = np.histogram(arr, bins=64, range=(0,255))
    hist = hist.astype(float) / (hist.sum()+1e-9)
    hog_vec = hog(arr, pixels_per_cell=(16,16), cells_per_block=(2,2), feature_vector=True)
    return np.hstack([hist, hog_vec])

# ‚îÄ‚îÄ‚îÄ 1. Veri Topla -----------------------------------------------------------
all_data = []
for cls in LABELS:
    folder = ROOT / cls
    all_data += gather_images(folder, LABELS[cls])

X_list, y_list = [], []
print("üîπ √ñzellik √ßƒ±karƒ±lƒ±yor‚Ä¶")
for p,lbl in all_data:
    feats = extract_features(p)
    if feats is not None:
        X_list.append(feats); y_list.append(lbl)

X = np.array(X_list); y = np.array(y_list)
print(f"Toplam {len(y)} √∂rnek, √∂zellik boyutu {X.shape[1]}")

# ‚îÄ‚îÄ‚îÄ 2. Train/Test -----------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=SEED)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc  = scaler.transform(X_test)

# ‚îÄ‚îÄ‚îÄ 3. Sklearn Model Havuzu -------------------------------------------------
MODELS = {
    "RandomForest": RandomForestClassifier(n_estimators=300, random_state=SEED, n_jobs=-1),
    "SVM":          SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=SEED),
    "KNN":          KNeighborsClassifier(n_neighbors=5),
    "XGBoost":      XGBClassifier(n_estimators=600, max_depth=10, learning_rate=0.1,
                                   subsample=0.9, colsample_bytree=0.9,
                                   objective='binary:logistic', eval_metric='logloss', n_jobs=-1)
}

summary_rows = []

for name, clf in MODELS.items():
    print(f"\n‚ñ∂Ô∏é {name} eƒüitiliyor‚Ä¶")
    if name in {"SVM", "KNN"}:
        clf.fit(X_train_sc, y_train)
        preds = clf.predict(X_test_sc)
        bundle = {"scaler": scaler, "clf": clf}
    else:
        clf.fit(X_train, y_train)
        preds = clf.predict(X_test)
        bundle = {"scaler": None, "clf": clf}

    acc = accuracy_score(y_test, preds)
    f1  = f1_score(y_test, preds, average='macro')
    summary_rows.append({"model": name, "accuracy": acc, "macro_f1": f1})

    # CM
    cm = confusion_matrix(y_test, preds)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)
    plt.title(f"{name} CM"); plt.tight_layout()
    plt.savefig(CM_DIR/f"{name}_cm.png", dpi=300); plt.close()

    joblib.dump(bundle, PROC / f"{name}.pkl")

# ‚îÄ‚îÄ‚îÄ 4. Opsiyonel CNN --------------------------------------------------------
if HAS_TF:
    print("\n‚ñ∂Ô∏é MobileNetV2 transfer learning (CNN) eƒüitiliyor‚Ä¶")
    # Basit data loader
    def img_tensor(path):
        img = Image.open(path).convert('RGB').resize((160,160))
        return np.array(img)/255.0

    X_imgs = np.array([img_tensor(p) for p,_ in all_data])
    y_imgs = np.array([lbl for _,lbl in all_data])
    X_tr, X_te, y_tr, y_te = train_test_split(X_imgs, y_imgs, test_size=0.2, stratify=y_imgs, random_state=SEED)

    base = MobileNetV2(include_top=False, input_shape=(160,160,3), weights='imagenet', pooling='avg')
    base.trainable = False
    model_cnn = Sequential([base, Dense(2, activation='softmax')])
    model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model_cnn.fit(X_tr, y_tr, epochs=5, batch_size=32, validation_split=0.1, verbose=2)
    preds = model_cnn.predict(X_te).argmax(axis=1)
    acc = accuracy_score(y_te, preds)
    f1  = f1_score(y_te, preds, average='macro')

    summary_rows.append({"model":"MobileNetV2","accuracy":acc,"macro_f1":f1})
    model_cnn.save(PROC/"MobileNetV2.h5")

    cm = confusion_matrix(y_te, preds)
    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)
    plt.title("MobileNetV2 CM"); plt.tight_layout()
    plt.savefig(CM_DIR/"MobileNetV2_cm.png", dpi=300); plt.close()
else:
    print("TensorFlow bulunamadƒ± ‚Üí CNN adƒ±mƒ± atlandƒ±.")

# ‚îÄ‚îÄ‚îÄ 5. √ñzet ve En ƒ∞yi Model -------------------------------------------------
summary_df = pd.DataFrame(summary_rows).sort_values("macro_f1", ascending=False)
summary_df.to_csv(PROC/"IoT_models_summary_v2.csv", index=False)

best_row = summary_df.iloc[0]
if best_row['model'] == 'MobileNetV2':
    shutil.copy(PROC/"MobileNetV2.h5", PROC/"best_model.h5")
else:
    shutil.copy(PROC/f"{best_row['model']}.pkl", PROC/"best_model.pkl")

print("\nüèÅ Eƒüitim tamamlandƒ± ‚Äì Sonu√ßlar:")
print(summary_df)
print(f"√áƒ±ktƒ±lar ‚Üí {PROC}")