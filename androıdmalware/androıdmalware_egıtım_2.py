import warnings, shutil, joblib, os
from pathlib import Path
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier

# â”€â”€â”€ Dosya YollarÄ± & Sabitler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CSV_PATH = Path(r"C:\Users\Ä°SO\Desktop\VERI_SETLERI\androÄ±dmalware\drebin-215-dataset-5560malware-9476-benign_1.csv")
BASE_DIR = CSV_PATH.parent
PROC_DIR = BASE_DIR / "processed"; PROC_DIR.mkdir(exist_ok=True)
CM_DIR   = PROC_DIR / "model_cms"; CM_DIR.mkdir(exist_ok=True)
LABEL_NAMES = ["Benign", "Malware"]
SEED = 42

if not CSV_PATH.exists():
    raise FileNotFoundError(f"CSV bulunamadÄ±: {CSV_PATH}")

# â”€â”€â”€ 1. Veri YÃ¼kle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv(CSV_PATH)
print("Temiz veri yÃ¼klendi:", df.shape)

X = df.drop(columns=["class"])
y = df["class"]

# â”€â”€â”€ 2. Train/Test BÃ¶l â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=SEED)

# Ã–lÃ§ekleyici (LR & KNN)
scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc  = scaler.transform(X_test)

# â”€â”€â”€ 3. Model Havuzu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = {
    "LogisticRegression": LogisticRegression(max_iter=1000, solver="saga", n_jobs=-1),
    "RandomForest":       RandomForestClassifier(n_estimators=150, random_state=SEED, n_jobs=-1),
    "KNN":                KNeighborsClassifier(n_neighbors=5),
    "XGBoost":            XGBClassifier(
                              n_estimators=600, max_depth=10, learning_rate=0.1,
                              subsample=0.9, colsample_bytree=0.9,
                              objective="binary:logistic", eval_metric="logloss",
                              random_state=SEED, n_jobs=-1)
}

summary = []

# â”€â”€â”€ 4. EÄŸitim DÃ¶ngÃ¼sÃ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for name, model in MODELS.items():
    print(f"\nâ–¶ï¸ {name} eÄŸitiliyorâ€¦")

    if name in {"LogisticRegression", "KNN"}:
        model.fit(X_train_sc, y_train)
        preds = model.predict(X_test_sc)
        bundle = {"scaler": scaler, "clf": model}
    else:
        model.fit(X_train, y_train)
        preds = model.predict(X_test)
        bundle = {"scaler": None, "clf": model}

    acc = accuracy_score(y_test, preds)
    f1  = f1_score(y_test, preds, average="macro")
    summary.append({"model": name, "accuracy": acc, "macro_f1": f1})

    # CM GÃ¶rseli
    cm = confusion_matrix(y_test, preds, labels=[0,1])
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=LABEL_NAMES, yticklabels=LABEL_NAMES)
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Tahmin"); plt.ylabel("GerÃ§ek")
    plt.tight_layout()
    plt.savefig(CM_DIR / f"{name}_cm.png", dpi=300)
    plt.close()

    # Model kaydet
    joblib.dump(bundle, PROC_DIR / f"{name}.pkl")
    print(f"   â†³ {PROC_DIR}/{name}.pkl (F1={f1:.3f})")

# â”€â”€â”€ 5. En Ä°yi Model & Ã–zet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
summary_df = pd.DataFrame(summary).sort_values("macro_f1", ascending=False)
summary_df.to_csv(BASE_DIR / "drebin_models_summary.csv", index=False)

best_name = summary_df.iloc[0]["model"]
shutil.copy(PROC_DIR / f"{best_name}.pkl", PROC_DIR / "best_model.pkl")
print(f"\nğŸ† En iyi model: {best_name} (F1={summary_df.iloc[0]['macro_f1']:.3f}) â†’ {PROC_DIR}/best_model.pkl")

print("\nâœ… EÄŸitim tamamlandÄ± â€“ SonuÃ§lar:")
print(summary_df)
print(f"TÃ¼m Ã§Ä±ktÄ±lar â†’ {PROC_DIR}")
